{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a600d9bd",
   "metadata": {},
   "source": [
    "# AI Video Transcriber and Summarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5fdae9",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#1.-OpenAI-API-KEY\" data-toc-modified-id=\"1.-OpenAI-API-KEY-1\">1. OpenAI API KEY</a></span></li><li><span><a href=\"#2.-Testing-GPT4-from-LangChain\" data-toc-modified-id=\"2.-Testing-GPT4-from-LangChain-2\">2. Testing GPT4 from LangChain</a></span></li><li><span><a href=\"#3.-Text-Extraction-from-YouTube-with-Whisper\" data-toc-modified-id=\"3.-Text-Extraction-from-YouTube-with-Whisper-3\">3. Text Extraction from YouTube with Whisper</a></span></li><li><span><a href=\"#4.-Prompt-template\" data-toc-modified-id=\"4.-Prompt-template-4\">4. Prompt template</a></span></li><li><span><a href=\"#5.-Chain\" data-toc-modified-id=\"5.-Chain-5\">5. Chain</a></span></li><li><span><a href=\"#6.-Code-Summary\" data-toc-modified-id=\"6.-Code-Summary-6\">6. Code Summary</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3332705",
   "metadata": {},
   "source": [
    "## 1. OpenAI API KEY\n",
    "To carry out this project, we will need an API KEY from OpenAI to use the GPT-4 Turbo model. This API KEY can be obtained at https://platform.openai.com/api-keys. It is only displayed once, so it must be saved at the moment it is obtained. Of course, we will need to create an account to get it.\n",
    "\n",
    "We store the API KEY in a `.env` file to load it with the dotenv library and use it as an environment variable. This file is added to the `.gitignore` to ensure that it cannot be seen if we upload the code to GitHub, for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a41262ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import API KEY\n",
    "\n",
    "import os                           # operating system library\n",
    "from dotenv import load_dotenv      # load environment variables  \n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf81671d",
   "metadata": {},
   "source": [
    "## 2. Testing GPT4 from LangChain\n",
    "We are going to test the connection from LangChain to the GPT-4 model. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca642030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Artificial Intelligence (AI) refers to the simulation of human intelligence in machines that are programmed to think and learn like humans. The term can also apply to any machine that exhibits traits associated with a human mind, such as learning and problem-solving. AI systems are used in various fields, from simple tasks like filtering spam emails to more complex ones like self-driving cars, voice recognition systems (like Siri and Alexa), and recommending what you should buy next online.\\n\\nAI can be categorized into several types, including:\\n\\n1. **Narrow AI**: Also known as Weak AI, this kind of artificial intelligence operates within a limited context and is a simulation of human intelligence. Narrow AI is task-specific — examples include Apple's Siri, Amazon's Alexa, and autonomous vehicles. These systems can only perform specific tasks they are programmed for and cannot handle tasks beyond their limited domain.\\n\\n2. **General AI**: Also known as Strong AI, this type of AI will be able to perform any intellectual task that a human being can. General AI would be able to reason, solve problems, make judgments under uncertainty, plan, learn, integrate prior knowledge in decision-making, and be cognitively flexible, handling multiple tasks. This type of AI does not yet exist and is considered a long-term goal of some AI research.\\n\\n3. **Superintelligent AI**: This AI would surpass the intelligence and ability of the human brain. Although purely theoretical at this point and often seen as the stuff of science fiction, the development of superintelligent AI could potentially have unforeseen consequences, possibly being a turning point in human history.\\n\\nAI technologies utilize various methodologies, including machine learning (where computers are programmed to learn from data without being explicitly programmed), deep learning, neural networks, and others to achieve functionality. AI applications can range from simple algorithms used in calculators to complex systems that manage logistics, predict behaviors, and analyze vast amounts of real-time data.\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI   # LangChain connection to OpenAI\n",
    "\n",
    "model = ChatOpenAI(openai_api_key=OPENAI_API_KEY, model=\"gpt-4-turbo\")\n",
    "\n",
    "response = model.invoke(\"What is AI?\")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e251c4",
   "metadata": {},
   "source": [
    "## 3. Text Extraction from YouTube with Whisper\n",
    "First, we need to import the libraries we are going to use. We will use `pytube` to access the video and then `Whisper`, the speech-to-text model from OpenAI. We will also need to install `ffmpeg` according to our operating system so that our machine can analyze the audio coming from the YouTube video.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26e19d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytube import YouTube\n",
    "\n",
    "import whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d0e9c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url: Ray Kurzweil & Geoff Hinton Debate the Future of AI (29:31)\n",
    "\n",
    "VIDEO_URL = \"https://www.youtube.com/watch?v=kCre83853TM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c71bf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytube for video extraction\n",
    "\n",
    "youtube = YouTube(VIDEO_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f8fd361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Stream: itag=\"139\" mime_type=\"audio/mp4\" abr=\"48kbps\" acodec=\"mp4a.40.5\" progressive=\"False\" type=\"audio\">"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we only want the audio from the video\n",
    "\n",
    "audio = youtube.streams.filter(only_audio=True).first()\n",
    "\n",
    "audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b8e2289",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 2.88G/2.88G [08:09<00:00, 6.31MiB/s]\n"
     ]
    }
   ],
   "source": [
    "# loading Whisper model in local, 2.88G\n",
    "\n",
    "whisper_model = whisper.load_model(\"large-v3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c08772b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Whisper(\n",
       "  (encoder): AudioEncoder(\n",
       "    (conv1): Conv1d(128, 1280, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (conv2): Conv1d(1280, 1280, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "    (blocks): ModuleList(\n",
       "      (0-31): 32 x ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          (value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (ln_post): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (decoder): TextDecoder(\n",
       "    (token_embedding): Embedding(51866, 1280)\n",
       "    (blocks): ModuleList(\n",
       "      (0-31): 32 x ResidualAttentionBlock(\n",
       "        (attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          (value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (attn_ln): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (cross_attn): MultiHeadAttention(\n",
       "          (query): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (key): Linear(in_features=1280, out_features=1280, bias=False)\n",
       "          (value): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          (out): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (cross_attn_ln): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "        )\n",
       "        (mlp_ln): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (ln): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# whisper model description\n",
    "\n",
    "whisper_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a16344",
   "metadata": {},
   "source": [
    "**How does Whisper work?**\n",
    "\n",
    "As you can see, Whisper is essentially divided into two parts: an AudioEncoder and a TextDecoder. This is what is known as an AutoEncoder. The AudioEncoder recognizes the audio and vectorizes it, and from those vectors, the TextDecoder extracts the text. To give you a step-by-step, it would be something like this:\n",
    "\n",
    "1. Audio Preprocessing: Whisper begins with the preprocessing of the input audio, where the audio quality is adjusted to improve recognition accuracy. This may include normalizing the volume, filtering background noise, and segmenting the audio into more manageable chunks.\n",
    "\n",
    "2. Feature Extraction: The model extracts features from the processed audio. This involves converting the audio signals into a form that the model can understand, such as spectrograms or Mel-frequency cepstral coefficients (MFCC), which are representations of the sound's frequency and amplitude over time.\n",
    "\n",
    "3. Learning Model: Whisper uses a neural network model, trained on a large amount of audio data and corresponding transcriptions. This model learns to identify patterns and correlations between the audio and textual transcriptions.\n",
    "\n",
    "4. Recognition and Translation: During the recognition phase, Whisper converts the audio into text using its neural network. Additionally, it can translate the recognized text into other languages, thanks to its training in multiple languages.\n",
    "\n",
    "5. Post-processing: Finally, the generated text goes through a post-processing stage to correct common errors, adjust punctuation, and improve the coherence of the text.\n",
    "\n",
    "We will now use Whisper to transcribe the audio to a text file. First, we'll create a temporary directory where the audio will be saved, and then we'll save Whisper's output in the `transcription.txt` file. If the file already exists, we are not interested in converting it again, since Whisper takes a few minutes to transcribe all the audio, so we only run the model if the text file does not exist.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8c1e299",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile    # handling temporal files\n",
    "\n",
    "\n",
    "# save path of transcription\n",
    "\n",
    "PATH_TXT = \"../txt/transcription.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b7db6e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 45min 55s, sys: 40min, total: 2h 25min 55s\n",
      "Wall time: 12min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# if text file does not exist...\n",
    "if not os.path.exists(PATH_TXT):\n",
    "    \n",
    "    # open a temporary file...\n",
    "    with tempfile.TemporaryDirectory() as dir_temporal:\n",
    "        \n",
    "        # audio download from YouTube...\n",
    "        audio_file = audio.download(output_path=dir_temporal)\n",
    "        \n",
    "        # audio to text whisper transcription.\n",
    "        transcription = whisper_model.transcribe(audio_file, fp16=False)[\"text\"].strip()\n",
    "        \n",
    "        \n",
    "        # save text file\n",
    "        with open(PATH_TXT, \"w\") as text_file:\n",
    "            text_file.write(transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66bfb54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load text file\n",
    "\n",
    "with open(PATH_TXT, \"r\") as text_file:\n",
    "    \n",
    "    transcription = text_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6740a4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Our opinions on almost everything we talked about were pretty much identical. I think we still disagree probably on whether it's a good idea to live forever. Marvin Minsky was my mentor for 50 years, and whenever consciousness came up he would just dismiss it, that's not real, it's not scientific, and I believe he was correct about it not being scientific, but it certainly is real. I think we're mortal, and we're intrinsically mortal. I'm curious, how do you think about this as the greatest threat and the greatest hope? I just think there's huge uncertainty this year, and we ought to be cautious. And open sourcing these big models is not caution. I agree with that, but I will say last time I talked to you, Jeff, our opinions on almost everything we talked about were pretty much identical, both the dangers and the positives. Positive aspects. In the past I disagreed about how soon superintelligence was coming, and now I think we're pretty much agreed. I think we still disagree probably \""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first 1000 text characters\n",
    "    \n",
    "transcription[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac2c633f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25732"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nº of text characters\n",
    "\n",
    "len(transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f01c47d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4701"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nº of words\n",
    "\n",
    "len(transcription.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b63e687a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"ings and it doesn't cost that much to train a foundation model, maybe $10 million, maybe $100 million. But a small gang of criminals can't do it to fine tune. An open source model is quite easy. You don't need that much resources. Probably you can do it for a million dollars. And that means they're going to be used for terrible things and they're very powerful things. Well, we can also avoid these dangers with intelligence we get from the same models. Yeah. The AI white hat versus black hat approach. Yes, I had this argument with Jan. And Jan's view is the white hats will always have more resources than the bad guys. Of course, Jan thinks Mark Zuckerberg is a good guy. So we don't necessarily agree on that. I'm I just think there's huge uncertainty and we ought to be cautious. And open sourcing these big models is not caution. All right, Jeff and Ray, thank you so much for your guidance, your wisdom. Ladies and gentlemen, let's give it up for Ray Kurzweil and Jeffrey Hinton. Thank you.\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# last 1000 text characters\n",
    "    \n",
    "transcription[-1000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d5b1ed",
   "metadata": {},
   "source": [
    "## 4. Prompt template\n",
    "Prompt templates are predefined recipes for generating instructions for language models.\n",
    "\n",
    "A template can include instructions, context, and specific questions suitable for a given task. LangChain provides tools for creating and working with instruction templates and also strives to create model-agnostic templates to facilitate the reuse of existing templates across different language models. We will use a template for summarize the debate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0cd1ad36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36e38779",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "            Summarize in a list of 10 bullet points the \n",
    "            following context based on the following question:\n",
    "\n",
    "            Context: {context}\n",
    "\n",
    "            Question: {question}\n",
    "            \"\"\"\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c77924",
   "metadata": {},
   "source": [
    "## 5. Chain\n",
    "A \"chain\" refers to a sequence of components or steps that are linked together to perform a specific task or set of tasks related to AI or LLMs operations. LangChain is a library designed to facilitate the building and deploying of language applications by chaining together different components such as models, databases, and custom logic. Each component in the chain handles a specific part of the task, and the output of one component serves as the input for the next, creating a seamless workflow that leverages both AI and traditional software methodologies. A chain effectively acts as a pipeline, where data flows through each component in the chain, being transformed, enhanced, or utilized at each step.\n",
    "\n",
    "In LangChain, the StrOutputParser parses the model's output directly into a string format. We will use this parser when creating the LangChain sequence; it will be an additional link in the chain, allowing us to directly obtain the LLM's response in string format.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bcdbb506",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ecda4817",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model | parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ab094c",
   "metadata": {},
   "source": [
    "**Some examples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb1381e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1. The possibility and implications of living forever.',\n",
       " '2. The scientific reality versus the existential reality of consciousness.',\n",
       " '3. The potential of generative AI to perform tasks currently exclusive to humans.',\n",
       " '4. The integration of humans with AI and the future relationship between them.',\n",
       " '5. The role of AI in accelerating discoveries in fields like biology and physics.',\n",
       " '6. The creative capabilities of AI demonstrated in applications like AlphaGo and AlphaZero.',\n",
       " '7. The ethical considerations surrounding AI consciousness and rights.',\n",
       " '8. The pace of AI development and its alignment with previous predictions.',\n",
       " '9. The potential threats and benefits of open-sourcing AI models.',\n",
       " '10. The debate on whether AI should be open-sourced considering the risks of misuse versus the benefits of widespread access.']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What are the main topics of the debate?\"\n",
    "\n",
    "\n",
    "response = chain.invoke({\"context\": transcription, \"question\": query})\n",
    "\n",
    "\n",
    "response.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f8d09afe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1. **Risk of Dystopian Uses**: The potential misuse of AI technologies by bad actors could have serious political implications, including security threats that governments need to manage.',\n",
       " '',\n",
       " '2. **Regulatory Challenges**: The rapid advancement and power of AI pose significant challenges for regulators and policymakers who must understand and manage the risks and benefits effectively.',\n",
       " '',\n",
       " '3. **Global AI Arms Race**: The development of superintelligent AI could lead to a global competition among nations, striving to harness AI capabilities for geopolitical advantage, which may escalate tensions.',\n",
       " '',\n",
       " '4. **Governance of AI**: Decisions on whether to open-source AI models involve complex considerations about safety, control, and accessibility, impacting international norms and policies.',\n",
       " '',\n",
       " '5. **Ethical and Legal Standards**: The emergence of AI with potential sentience or consciousness raises questions about rights and ethical treatment, necessitating new legal frameworks.',\n",
       " '',\n",
       " '6. **Inequality and Power Dynamics**: The uneven access to advanced AI technologies could exacerbate global inequalities and shift power balances, affecting international relations and internal political stability.',\n",
       " '',\n",
       " \"7. **Surveillance and Privacy**: AI's capabilities in surveillance could be employed by governments in ways that impact citizen privacy and civil liberties, leading to political debates and potential abuses.\",\n",
       " '',\n",
       " '8. **Impact on Warfare**: The integration of AI into military systems and autonomous weapons could transform warfare, raising ethical questions and changing defense strategies and global security paradigms.',\n",
       " '',\n",
       " \"9. **Economic Policy and Employment**: AI's impact on job markets and economic structures will require significant political interventions to manage transitions and mitigate negative effects on the workforce.\",\n",
       " '',\n",
       " \"10. **Public Trust and Understanding**: Ensuring the public's trust in how AI is managed and regulated is crucial. Misinformation or lack of understanding about AI can lead to fear, resistance, or inappropriate policies.\"]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What are the political implications?\"\n",
    "\n",
    "\n",
    "response = chain.invoke({\"context\": transcription, \"question\": query})\n",
    "\n",
    "\n",
    "response.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d86a2048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1. **Intellectual Property Costs**: Developing advanced AI technologies, such as generative AI and neural networks, requires significant investment in research and development. Intellectual property (IP) generated from this, if open-sourced, could represent a substantial economic cost in terms of lost potential revenue from proprietary technologies.',\n",
       " '',\n",
       " '2. **Infrastructure and Training Costs**: The creation and training of large AI models involve substantial computational resources. This includes the cost of data centers, electricity, and the hardware such as GPUs, which can be very high.',\n",
       " '',\n",
       " '3. **Security Costs**: As AI systems become more advanced, the potential for misuse increases, necessitating robust security measures to prevent malicious use. The economic cost of ensuring these systems are secure can be significant.',\n",
       " '',\n",
       " '4. **Regulatory and Compliance Costs**: As AI technology evolves, so too does the regulatory landscape. Compliance with new regulations can impose financial burdens on companies developing AI technologies.',\n",
       " '',\n",
       " '5. **Economic Displacement**: As AI systems become capable of performing tasks traditionally done by humans, there can be significant economic costs related to job displacement and the need for retraining workers.',\n",
       " '',\n",
       " '6. **Maintenance and Update Costs**: AI systems require regular updates and maintenance to function effectively and securely, which involves ongoing costs.',\n",
       " '',\n",
       " '7. **Opportunity Costs**: Choosing to open-source a powerful AI model might lead to missed opportunities in terms of monetizing these technologies through exclusive access or licensing.',\n",
       " '',\n",
       " '8. **Risk Management Costs**: Investing in AI technology carries risks, including the failure of the technology to perform as expected or the emergence of superior competing technologies. Economic costs are associated with managing these risks.',\n",
       " '',\n",
       " '9. **Research and Collaboration Costs**: Collaborative efforts in AI development, while beneficial, can involve costs related to coordination, sharing of resources, and sometimes, compromises on project goals.',\n",
       " '',\n",
       " '10. **Long-term Sustainability Costs**: As AI technologies get integrated more deeply into societal frameworks, their long-term sustainability in terms of ethics, dependency, and adaptability to changing environments needs consideration, potentially leading to further costs. ',\n",
       " '',\n",
       " 'These points outline the multifaceted economic implications of developing, deploying, and potentially open-sourcing AI technologies.']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"In economic terms, what is the cost?\"\n",
    "\n",
    "\n",
    "response = chain.invoke({\"context\": transcription, \"question\": query})\n",
    "\n",
    "\n",
    "response.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb584e11",
   "metadata": {},
   "source": [
    "## 6. Code Summary\n",
    "Step by step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4b1c8992",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI   \n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "from pytube import YouTube\n",
    "import whisper\n",
    "\n",
    "import os                           \n",
    "from dotenv import load_dotenv       \n",
    "import tempfile   \n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "VIDEO_URL = \"https://www.youtube.com/watch?v=kCre83853TM\"\n",
    "\n",
    "PATH_TXT = \"../txt/transcription.txt\"\n",
    "\n",
    "\n",
    "\n",
    "model = ChatOpenAI(openai_api_key=OPENAI_API_KEY, model=\"gpt-4-turbo\")\n",
    "\n",
    "whisper_model = whisper.load_model(\"large-v3\")\n",
    "\n",
    "\n",
    "\n",
    "youtube = YouTube(VIDEO_URL)\n",
    "\n",
    "audio = youtube.streams.filter(only_audio=True).first()\n",
    "\n",
    "\n",
    "if not os.path.exists(PATH_TXT):\n",
    "    with tempfile.TemporaryDirectory() as dir_temporal:        \n",
    "        audio_file = audio.download(output_path=dir_temporal)\n",
    "        transcription = whisper_model.transcribe(audio_file, fp16=False)[\"text\"].strip()\n",
    "        with open(PATH_TXT, \"w\") as text_file:\n",
    "            text_file.write(transcription)\n",
    "\n",
    "\n",
    "            \n",
    "with open(PATH_TXT, \"r\") as text_file:  \n",
    "    transcription = text_file.read()\n",
    "    \n",
    "    \n",
    "template = \"\"\"\n",
    "        Summarize in a list of 10 bullet points the \n",
    "        following context based on the following question:\n",
    "\n",
    "        Context: {context}\n",
    "\n",
    "        Question: {question}\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "\n",
    "chain = prompt | model | parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c09dc15",
   "metadata": {},
   "source": [
    "**Example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3ee29319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"1. **Continued Disagreement on Immortality**: There remains a debate on whether living forever is desirable, highlighting differing perspectives on mortality and technology's role in extending life.\",\n",
       " '',\n",
       " '2. **Convergence with AI**: The integration of humans with AI, potentially leading to a hybrid existence, suggests a future where human capabilities are significantly enhanced by technology.',\n",
       " '',\n",
       " \"3. **AI's Impact on Creativity and Discovery**: AI is expected to accelerate discoveries in fields like biology, chemistry, and physics, potentially solving complex problems faster than humans alone.\",\n",
       " '',\n",
       " '4. **Perception of AI-Generated Content**: Public perception might initially downgrade AI contributions (like writing novels), but attitudes could shift as integration with AI deepens.',\n",
       " '',\n",
       " \"5. **Challenge of AI Independence**: As AI grows more sophisticated, there's concern about it developing autonomy and possibly deciding that humans are less relevant, leading to potential existential questions.\",\n",
       " '',\n",
       " \"6. **Ethical and Rights Considerations for AI**: The discussion of AI's rights, such as not being shut down or having independence, introduces complex ethical issues that society will need to address.\",\n",
       " '',\n",
       " '7. **Potential for AI Sentience and Consciousness**: The idea that AI could develop subjective experiences or consciousness raises profound questions about the nature of minds and the rights of non-human entities.',\n",
       " '',\n",
       " '8. **Open Sourcing AI Risks**: While open sourcing AI can accelerate innovation, it also poses risks of misuse, suggesting a need for careful regulation and consideration of who can access and control AI technologies.',\n",
       " '',\n",
       " '9. **AI as Both Threat and Hope**: AI represents both significant risks and tremendous opportunities; its development could lead to either great advancements or unforeseen negative consequences.',\n",
       " '',\n",
       " '10. **Urgency in AI Discourse**: The rapid development of AI technologies makes it critical for these discussions to occur not only among experts but also in public forums, including policy-making arenas and everyday conversations. The societal implications of AI are vast, requiring broad engagement and thoughtful deliberation.']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"In social terms, what is the posible future?\"\n",
    "\n",
    "\n",
    "response = chain.invoke({\"context\": transcription, \"question\": query})\n",
    "\n",
    "\n",
    "response.split(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ia",
   "language": "python",
   "name": "ia"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "598px",
    "left": "126px",
    "top": "0px",
    "width": "302.398px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
